1
00:00:56,381 --> 00:00:59,381
你現在2023年大巨文革を用いて応用講座

2
00:00:59,381 --> 00:01:04,391
第5回演習を担当します小西と申します。よろしくお願いします。

3
00:07:34,013 --> 00:07:36,783
本演習は、そこまで手を動かすものはないので

4
00:07:37,423 --> 00:07:40,943
ま、ゆっくり聞いて理解していただければなという風に思います。

5
00:07:41,293 --> 00:08:01,003
で、まあこの講義を通して、インタープリタビリティ研究の分野にをの分野のま、研究をしていただければまあこのブラックボックス、AIの安全性や信頼性に貢献できる研究者、ま、研究のきっかけになるかなという風に思います。

6
00:08:03,163 --> 00:08:08,233
事前準備は、このノートブックはGoogle Collabで実行することを想定しています。

7
00:08:08,793 --> 00:08:14,243
で、今回は、メディア版でも使えるようにT4 GPUを選択してください。

8
00:08:20,013 --> 00:08:29,863
で、繋がって、このNVIDIA SML -aのコマンドを打って、アウトプットがT4であれば大丈夫です。

9
00:08:35,633 --> 00:08:35,763
はい。

10
00:08:36,543 --> 00:08:42,753
インストールできましたら、次をトランスフォーマーレンズのインストールに進んでいきたいという風に思います。

11
00:08:43,453 --> 00:08:52,943
ロジットレンズという手法の中でも、ま、様々なライブラリーが存在していて、本講義では、本演習では、ま、トランスフォーマーレンズというものを利用します。

12
00:08:55,303 --> 00:09:06,623
トランスフォーマーレンズとは、アンソロピックとクラウドデコードとかクラウデンを開発している企業ですね、の、研究者が開発したインタープリタビリティ研究用のライブラリーとなっています。

13
00:09:07,313 --> 00:09:14,753
ロジットレンズを、ま、簡単に実装するツールとして、ま、ある程度広く利用されているものだかなという風に思います。

14
00:09:17,313 --> 00:09:28,323
具体的に何をするかっていうのを、ま、ちょっとだけ話すと、ま、トランスフォーマーモデルの中間層の活性化アクティベーションを容易にしとこないというようなライブラリーとなっています。

15
00:09:28,843 --> 00:09:42,913
で、ま、GPT 2、GPT Neoなどの、ま、主要なオープンモデルに対応しており、で、今回はGoogle Collabの環境下でも行うんで、GPT 2を利用して行っていきたいなという風に思います。

16
00:09:43,473 --> 00:09:46,923
もしよかったらトランスフォーマーレンズをインストールしておいてください。

17
00:09:59,683 --> 00:10:00,103
はい。

18
00:10:00,683 --> 00:10:08,943
それではトランスフォーマーレンズをインストールすると、ナンパイのバージョンが1.26.4にダウングレードされます。

19
00:10:09,303 --> 00:10:15,703
ま、これはトランスフォーマーレンズが少し古いライブラリーなので、ま、そのせいでダウングレードをされてしまいます。

20
00:10:17,143 --> 00:10:25,563
ま、このままではパンダスなと他のライブラリーと競合してしまうんで、ランタイムの再起動で、ま、リセットを行ってください。

21
00:10:28,483 --> 00:10:33,523
で、今一度スタートできれば大丈夫です。

22
00:10:35,423 --> 00:10:41,203
次は、今回利用するトランスフォーマーレンズのライブラリーのインストールを行ってください。

23
00:10:41,743 --> 00:10:47,703
で、ま、ま、ナンパイだとか、ここでトランスフォーマーレンズをここでインストールする感じです。

24
00:11:13,313 --> 00:11:13,543
はい。

25
00:11:14,283 --> 00:11:19,853
インストールできましたら、次をGPT 2スモールのモデルをインストールしてください。

26
00:11:37,203 --> 00:11:37,503
はい。

27
00:11:38,403 --> 00:11:39,373
インストールできたら

28
00:11:40,243 --> 00:11:53,433
ま、ちょっとこのインストールのアウトプットを見てみると分かる通り、ま、モデルがGPT 2で、レイヤーが結構12レイヤーで、ま、少ないレイヤーから、ま、小さめのモデルだからっていうのが分かります。

29
00:11:54,583 --> 00:11:59,183
で、ま、ポイントとしてはGPT 2スモールは12層トランスフォーマーデコーダーです。

30
00:12:01,233 --> 00:12:08,243
で、ま、この後、このモデルで、ま、ロジットレンズっていうのをとして、色々と観察実行していきたいと、観察していきたいと思います。

31
00:12:14,640 --> 00:12:21,800
まず、徐々にとして、ブラックボックスとしてのLLMについて少し考えていければなという風に思います。

32
00:12:23,730 --> 00:12:32,870
で、ま、まずロジットレンズを利用しないて、内部構造をま、意識せずにGPT 2をテキスト生成モデルとして使用してみましょう。

33
00:12:33,670 --> 00:12:52,190
で、今回は最も確率の高いトークンを選択するクイーディコーディングの方法でトークンの出力をし、フューショットプロンプティングというような手法をすることで、ま、欲しいアウトプットを出せるように、欲しい生成単語を出せるようにします。

34
00:12:53,490 --> 00:12:56,360
で、ここ、この例が分かりやすいんですけども

35
00:12:57,480 --> 00:13:12,710
ま、最初最初の2つに、最初に2つで入れて、で、そのと欲しいキャピタオブジャパニーズのようにして、で、ま、この前に具体例があるので、ま、GPT 2によっても、ま、結構このアウトプットが特許だってのが分かりやすいような仕組みになっています。

36
00:13:13,670 --> 00:13:27,990
で、この理由としてはGPT 2スモールので、ま、このようなフューショットプロンプティングをしてあげることによって、ま、より欲しいデータが、アウトプットが出すことができるというように、ていうのことがま、背景としてあります。

37
00:13:29,600 --> 00:13:32,490
で、リコーディングをセットアップします。

38
00:13:33,360 --> 00:13:38,980
で、セットアップした後、テキスト生成を少し、ま、2回ほどちょっとやってみようかなという風に思います。

39
00:13:40,680 --> 00:13:42,880
で、はい、アウトプット出ましたね。

40
00:13:42,880 --> 00:13:45,430
で、ま、アンサーは特許になったってことが分かると思います。

41
00:13:46,280 --> 00:14:00,940
で、ま、これは、ま、もちろんですね。ザキャピタルオブジャーマニーイズバーリン、ザキャピタルオブフランスイズパリス、ザキャピタルオブジャパンイズ、で、ま、それが、ま、もちろん日本の首都は、ま、東京なので、ま、東京という風に出てきたという風に思います。

42
00:14:02,800 --> 00:14:06,440
で、その後、ま、同様に少し試してみたいと思います。

43
00:14:08,210 --> 00:14:16,200
で、今回は、ま、3つプロンプトを別々に出して、で、ま、全て欲しいデータができたかなという風に思います。

44
00:14:18,650 --> 00:14:23,000
で、ま、GPT 2スモードが結構小さいモデルなので

45
00:14:23,790 --> 00:14:32,190
逆にフューショットを消してみたらどうなるのかっていうのとか、ま、お時間があれば、ちょっとプロンプトで試行してみて。

46
00:14:36,440 --> 00:14:36,740
はい。

47
00:14:38,620 --> 00:14:47,020
では、先ほどのこのプロンプトとアンサーが、ま、東京であったりとか、ま、欲しいものが出たっていうのが、ま、背景としてあったかなという風に思うんですけれども、

48
00:14:48,540 --> 00:14:57,630
ま、なぜGPT 2が、ま、東京、ここでは大社って言いますね。東京、なという正しい答えを出力したのかっていうのをちょっと考えていきたいという風に思います。

49
00:14:58,600 --> 00:15:05,000
ま、入力直後から東京を予測しているのか、途中のレイヤーで徐々に答えが形成されるのか。

50
00:15:05,430 --> 00:15:10,240
で、またどのレイヤーが具体的な知識を持っているのかっていうのが気になると思います。

51
00:15:10,670 --> 00:15:15,020
で、ま、これを調べる手法っていうのがロジットレンジ。

52
00:15:15,020 --> 00:15:25,750
っていう手法です。で、ま、これを行うことによって、ま、これな発展版とか、ま、たちで、ま、様々なAIの信頼性だったりとか安全性っていうのを担保しようっていうような形になってます。

53
00:15:32,440 --> 00:15:37,630
で、ま、ロジットレンジの理論的背景について少し説明できればなという風に思います。

54
00:15:37,970 --> 00:16:09,830
ま、まず、ま、トランスフォーマーの構造を、ま、簡単に説明すると、ま、インプットがありまして、で、それをマストークンにします。で、その後トランスフォーマーを、今回の場合だと、12レイヤーですね。12レイヤーを通したと、12レイヤーを通したと、ま、アンビリングを通して最終的なアウトプットをロジット出して、で、ま、今回はキャピタルオブジャパンイーズの場合だったので、ま、もちろん東京が出ますよねっていうような仕組みになってるかなという風に思います。

55
00:16:11,540 --> 00:16:16,730
で、ここで重要なポイントとしては、これら各レイヤーは非伝ステートを更新します。

56
00:16:17,800 --> 00:16:28,900
で、ま、これだけで、ま、通常は、ま、最終的な、最終レイヤーの出力のみが、アンエンベディング層に渡されて、生成に、ま、生成分として出力されます。

57
00:16:30,220 --> 00:16:42,940
また、中間レイヤーの非伝ステートは途中経過として忘れられるっていうのも、ま、トランスフォーマーデコーダーのポイント、ま、今回のロジットレンジを利用するにおいて、ま、重要なポイントとなっております。

58
00:16:45,340 --> 00:16:53,880
では、ま、今までテキスト生成を少ししてみたりとか、ま、ロジットレンジにおけるトランスフォーマー構造について学習してきたと思います。

59
00:16:55,590 --> 00:16:58,950
で、ここで、ま、本題のロジットレンジのRについて紹介します。

60
00:16:59,790 --> 00:17:03,160
ま、ロジットレンジは2022年に提案されました。

61
00:17:03,790 --> 00:17:23,940
通常アンエンベディング、これですね、は、最終レイヤーの非伝ステートのみに適用するんですけれども、逆にこのアンエンベディングを最終レイヤー以外のレイヤーにも適用させれば、そのレイヤーごとの予測がで、をえることができるんじゃないか、除くことができるんじゃないかっていうのを考えたのが、このロジットレンジという手法です。

62
00:17:24,530 --> 00:17:29,200
数式表現でいうと、ま、このような形になっているかなという風に思います。

63
00:17:30,730 --> 00:17:41,270
なので、これか、これかのおかげで、各レイヤーレベルなんですが、ま、各レイヤーレベルでの次のトークン予測の確率分布っていうのが得ることができるできます。

64
00:17:44,790 --> 00:17:59,570
で、ま、具体的な実装にする前に、ま、ヒントというか、ま、情報提供をすると、ま、ロジットレンジを読いた論文ではトランスフォーマーの各レイヤーことの役割を担っているってことが示唆されています。

65
00:18:00,380 --> 00:18:19,950
ま、浅いレイヤーでいうと、予測が不安定で文法的に妥当なトークンが上位に来やすい。中間レイヤーでいうと、文脈に関連するトークンが徐々に上位に現れ始めて、深いレイヤー、ま、最終的なアウトプットに近いレイヤーは、ま、ちゃんとした予測に帰属しているかなという形です。

66
00:18:20,680 --> 00:18:26,710
で、またで、またイタティブインファレンス仮説っていうものが存在します。

67
00:18:27,780 --> 00:18:42,500
で、またこれはトランスフォーマーがイタティブインファレンスを行っているという、ま、仮説ですね。を提唱しています。ま、各レイヤーが前のレイヤーの出力を洗練させて、で、段階的により正解に近づいていくというような、ま、仮説、ま、アイデアですね。

68
00:18:46,260 --> 00:19:02,460
で、はい。で、ま、ここから分かったこととしては、ま、ロジットレンスっていうものを途中の非伝ステートにアンベリングをかけて予測をすることも行っている、ま、手法だっていうのを、ま、理解できたかなという風に思います。

69
00:19:02,740 --> 00:19:17,770
で、ま、実験する前としては、実験する前の、ま、情報提供としては、ま、このような形で、ま、浅いレイヤーから、ま、このような風に、ま、段階的により正確に近いトークンに生成が行われているっていうのが分かると思います。

70
00:19:23,803 --> 00:19:27,513
で、実際にロジットレンズの関数の実装から移っていきたいと、思います。

71
00:19:28,683 --> 00:19:41,203
で、これは、成功研究のトランスフォーマーレンズのドキュメントが引っ張ってきてるものなので、ま、具体的な、ま、詳しい行動を見たいっていう方は、このコマンド、このリンクに見ていただければなという風に思います。

72
00:19:43,493 --> 00:19:46,653
で、ここで、ロジットレンズの関数を定義します。

73
00:19:49,303 --> 00:19:53,493
では実際にロジットレンズの実行について少しやっていきたいなという風に思います。

74
00:19:54,353 --> 00:20:06,473
で、これは先ほどと同じプロンプトですね。まずフューショットがあって、で、そのクオリティ、ま、これ実際に欲しい、実際に欲しいプロンプトです。キャピタルオブジャパンイズ。

75
00:20:08,273 --> 00:20:11,533
で、はい、実行してみました。

76
00:20:14,793 --> 00:20:22,833
で、今回はこの関数を定義してるので、ま、このようなテーブルでできたと思います。

77
00:20:24,203 --> 00:20:25,723
これについて少し説明したいなと思います。

78
00:20:26,823 --> 00:20:44,983
で、このテーブルはどうやって見ればいいかっていうと、ま、レイヤーがあって、で、これの浅いとこから1番11、1番深いところまであります。で、このナンバーワン、ナンバーツー、ナンバーシー、ナンバーフォー、ナンバーファイブっていうのは、ま、そのレイヤーの非伝ステートにアンエンベディングをかけた際の1番高い確率であったトークンです。

79
00:20:45,983 --> 00:21:00,503
で、ま、最初の法案は、先ほどと同じように結構その文法的な生成文が出てから、ま、生成単語が出てからという風に思います。

80
00:21:03,043 --> 00:21:07,953
で、ま、これについて少し、少しちょっと問題を出ししたいと思います。

81
00:21:09,723 --> 00:21:18,523
クエスチョンワンが東京で、クエスチョンツー、ま、これについて30秒ほど考えていただければなという風に思います。

82
00:21:42,473 --> 00:21:45,833
はい。では、ま、簡単に答え合わせをしたいなっていう風に

83
00:21:47,603 --> 00:21:48,333
をしていきます。

84
00:21:49,603 --> 00:21:55,753
ま、クエスチョンワンは東京がナンバーワンで、最高期のはレイヤー8からですね。

85
00:21:57,283 --> 00:22:07,813
で、ま、浅いレイヤーはどうようなトークンが予測されているか、ちょっと先を耐えを言ってしまったんですけれども、ま、文法的なトークンが生成されているっていうのが見て取れると思います。

86
00:22:09,563 --> 00:22:15,313
クエスチョン3はレイヤーが不運に応じて、どう変化しているかですね。

87
00:22:15,833 --> 00:22:29,243
で、ここで、最初がまず27、30って感じで、で、1つ前は10レイヤーまで、東京が95.4%って、ま、ほぼこれ確定だろみたいな感じになっているかなと思うんですけれども、レイヤー11でちょっとガクッと落ちて51.5%になっているかなという風に思います。

88
00:22:29,883 --> 00:22:42,573
で、これについては後ほど、なぜこういう風になっているのかっていうのを後ほど申すので、ま、なんでこうなっているだろうなっていうのは、ま、自分の中で少し今のうちに、ま、いろんなアイデアを出していただければ、ま、での理解が深まるかなという風に思います。

89
00:22:54,343 --> 00:23:02,153
で、今回は、ま、テーブルで見たんですけれども、やはりこのテーブルだと少し見にくいので、ま、化をしておきたいという風に思います。

90
00:23:03,513 --> 00:23:08,703
ま、ヒートマップとオデセングラフですね。で、これで定義をします。

91
00:23:13,913 --> 00:23:14,243
はい。

92
00:23:14,943 --> 00:23:25,753
で、ま、この今はヒートマップとオデセングラフのものを定義したので、ま、これを使って色々なプロンプトの実験をしていきたいなと思います。

93
00:23:27,273 --> 00:23:37,423
で、これは同様ですね。先ほどはザキャピタルオブイタリイズ、このジャパンだった、ま、イタリア、イタリアに変えただけなんですけれども、で、アウト、アウトプットを見てみましょう。

94
00:23:43,303 --> 00:23:43,593
はい。

95
00:23:46,263 --> 00:23:50,973
せっかくなので、このヒートマップも見ていきたいなと思います。

96
00:23:54,583 --> 00:23:54,873
はい。

97
00:23:56,873 --> 00:24:09,403
え、ま、もしこの最初の最初のこれはフューショットプロンプティング用なので、ま、無視していただいて、で、ここを見ていただければなという風に思います。

98
00:24:10,033 --> 00:24:25,703
で、この1番右のこの層が、はい、1番上のこの層が、今回生成の層となっています。

99
00:24:26,673 --> 00:24:37,703
で、ま、レイヤー0はキャピタルオブイタリイズの次のものがナウでいいんじゃないかっていう風に仮説、っていう風に、モデルの仮説が出ています。

100
00:24:38,203 --> 00:24:57,483
で、その後、段階的にナウ、ノットナウ、オールソーノットノットオールソーで、レイヤー7ぐらいですね。これはナウです。7からロームが具体的な治療が並べてきて、で、その後ドーム、ノーム、ノーム、ミラン、ドームで最終的にアウトプットはドームっていう風になっています。

101
00:25:08,343 --> 00:25:28,883
それ同様に、ローム、ロームで、で、なんか10レイヤーで1回ミランが出てきました。なぜなんだ。

102
00:25:29,783 --> 00:25:46,653
ま、こういう、なぜこういうのを、なぜドームからミランになったのかっていうのは、ま、ロジットレンズではちょっと見てないこともあり、で、ま、これは、ま、1つの課題、ロジットレンズの課題ではありますね。

103
00:25:46,653 --> 00:26:04,643
で、ま、なぜ見れないかっていうと、ま、先ほど述べたように、ま、レイヤーごとでしかアウトプット分からないので、ま、具体的なニュードンレベルの解析ができない、解読ができないっていうのは、ま、この課題の1つではあります。ですけど最終的なアウトプットはドームで、ま、正しいそうなので、ま、そうかという風に思います。

104
00:26:05,483 --> 00:26:14,643
で、ま、ヒートマップもあるので、ま、どのトークンがどういう風な形になっているのかなっていうのを、ま、少し見ていただければなという風に思います。

105
00:26:17,203 --> 00:26:26,633
で、ま、オレセングラフがやはり1番分かりやすいので、次のこの文法予測と、実験2な、実験3はオレセングラフで説明できればなという風に思います。

106
00:26:27,513 --> 00:26:28,493
では次に行きますね。

107
00:26:30,683 --> 00:26:33,753
はい。プロンプトはif I will bar I would。

108
00:26:33,753 --> 00:26:43,463
で、ま、日本語訳すると、ま、自分が鳥だったら、自分は何々をしたいみたいな感じのプロンプトですね。

109
00:26:44,053 --> 00:26:58,073
で、ま、自分だったら、ま、空を飛んでみたいんで、ま、空を飛んでみるっていうのがやっぱ、社会的に一般的な答えなのかなっていう風な、ま、予測をま、自分たちでし、で、ま、実践し、生成しています。

110
00:27:00,313 --> 00:27:08,793
で、アウトプットは、そうですね。今回はBが1番最初に出ましたね。

111
00:27:11,573 --> 00:27:37,703
ま、これはあれですね。ま、文章理解として、あの、If I were a bird I wouldなので、ま、自分が鳥だったら、自分は飛びたいっていう、ま、アウトプットも、ま、文脈も理解できますし、また同時に自分はなしになってみたいっていう意味での、このBが生成されているのかなという風に思います。

112
00:27:39,943 --> 00:27:41,293
で、オレセングラフで見てみると、

113
00:27:42,333 --> 00:27:45,413
ま、最初はI would neverが結構強かったですね。

114
00:27:46,743 --> 00:27:51,203
で、ま、ネバーだけどB、B、B、B、Bで最終的には、ま、Bが1番強かった。

115
00:27:51,753 --> 00:28:13,293
で、ま、こういう風に見てみると、ま、その文法理解的なものが今回が結構、文法生成ですね。文法生成が今回は、あの、プロンプト的にもアウトプットがあったかなという風に思うので、ま、最初らへんから、ま、答えが現れているかなっていうような形ですね。

116
00:28:14,243 --> 00:28:26,673
で、ま、フライは具体的には、最後の、中盤レイヤーで初めて出てきたっていう感じでしたね。ですけど、このグラフを

117
00:28:27,653 --> 00:28:34,813
見て限り、も、最初、中盤レイヤーから出てきたっていう感じだと思います。

118
00:28:35,763 --> 00:28:46,823
で、ま、フライの具体的なパーセンテージ、レイヤー0から知りたいっていう方は、ま、まとめたプログラムを、もし時間があれば組んであげてっていう風な形でお願いします。

119
00:28:48,733 --> 00:28:53,423
はい。では、最後の2つの実験ですね。

120
00:28:55,593 --> 00:28:57,693
最後のは文脈依存性について見ていきたいと思います。

121
00:28:59,043 --> 00:29:02,303
ま、バンクは銀行と河辺の療法で意味を持ちます。

122
00:29:02,693 --> 00:29:04,013
です、これ銀行ですね。

123
00:29:04,563 --> 00:29:09,143
で、ま、文脈によって、モデルの予測がどのように変わるかっていうのを観察したいなという風に思います。

124
00:29:09,923 --> 00:29:14,753
で、まずコンテクスト1は、I went to the bank to depositなので、やっぱりバンクですね。

125
00:29:15,643 --> 00:29:18,523
で、これ文脈的なものを見てみると、

126
00:29:27,473 --> 00:29:37,703
I went to the bank to depositなので、やっぱこの文脈はバンクなので、マニーが来やすいなっていうのが、ま、これを見てみると分かるかなと思います。

127
00:29:38,423 --> 00:29:43,443
で、ま、レイヤー7かな、マニーなんですけど、ま、レイヤー11がマイが勝ったって感じですね。

128
00:29:45,473 --> 00:29:51,553
なので、ま、多分I went to the bank to deposit my moneyみたいな、生成やってるからという風に思います。

129
00:29:51,963 --> 00:29:59,333
で、2つ目は逆にこの前にリバーバンクってなってるので、ま、これはもちろんカブなよねっていうものなのかなと思います。

130
00:29:59,793 --> 00:30:08,443
The river bank was covered withで、この生成は文書生成ですね。Rになりましたね。

131
00:30:10,753 --> 00:30:14,833
で、ま、これは文法的な部分でアウトプットがとったかなという風に思います。

132
00:30:15,693 --> 00:30:29,663
ま、結構色々な種類でこのパーセンテージっていうのは途中の、アンビディングの生成、出力っていうのはすごく変わってくると思うので、これはいろいろ試していただければなという風に思います。

133
00:30:31,103 --> 00:30:36,443
で、最後の時間的にも教えたいので、最後の演習をしていきたいと思います。

134
00:30:37,003 --> 00:30:41,203
GPT 2は2019年のデータで行っています。

135
00:30:42,393 --> 00:30:54,773
ま、なので、ま、まず、そもそもレイヤー質が少ないので、マイナーな国の首都であったりとか、最近変わった情報だ、曖昧な質問っていうのは、出力は難しいかなという風に思います。

136
00:30:55,423 --> 00:30:59,963
で、今回はカラクシタンですね。カラクシタンの人はどこですかっていうのを見てみます。

137
00:31:04,503 --> 00:31:09,693
で、カラクシタンの人は今回Kっていうアウトプットになりましたね。

138
00:31:10,713 --> 00:31:24,203
で、ま、これを見てみる限り、モデルにカラクシタンのキャピタル、のデータがなかったっていうのが、分かかなという風に思います。

139
00:31:28,473 --> 00:31:29,973
結構面白いし、てからという風に思います。

140
00:31:30,363 --> 00:31:42,283
で、ま、具体的な本当の答えはアストなんですけれども、ま、アスとが出てきて、その後アスとだがうまく出てこなかったかなという感じかなと思います。

141
00:31:43,303 --> 00:31:51,203
で、はい、最後、ま、色々とプロンプトを変えてみたりとかした感じで色々試していただければなという風に思います。

142
00:31:56,381 --> 00:32:02,401
最後、少し簡潔に今回のこの講義の結論述べといていきたいと、思います。

143
00:32:03,811 --> 00:32:13,911
で、最初の方で述べた最終層でなぜか確率がすごく下がってしまう理由ですね。今回の場合はカラクシタンが85%だったり、なぜかKになって10%になってしまった。

144
00:32:14,401 --> 00:32:22,661
で、ま、この理由として考えられるのは、最終層は次のトークン予測だけでなく、その先の生成にも役立つ情報をエンコードしているから。

145
00:32:23,171 --> 00:32:29,001
中間層の非伝ステートを最終層では表現空間が微妙に異なる可能性があるから。

146
00:32:31,791 --> 00:32:35,761
また、モデルがカドな司確信を避け、類時トークン。

147
00:32:36,001 --> 00:32:37,791
これはおそらく京都って言っている理由としては、

148
00:32:40,231 --> 00:32:52,691
この1番上のです、これのこの先のこのテストの場合では、東京が出たんですけど、同時に類トークンの大阪だったりとか京都が出てきましたねっていう話ですね。

149
00:32:56,581 --> 00:33:01,571
はい、すいません。ま、類トークンにも確率を分させるから。

150
00:33:01,891 --> 00:33:02,071
っていうな

151
00:33:02,301 --> 00:33:02,591
仮説です。

152
00:33:02,951 --> 00:33:16,661
ですけど、これの課題としては、この考えられる理由でしか出さなくて、実際どのような仕組みになっているのかっていうのは、ま、見つけることができないっていうのがロジットレンズの課題です。

153
00:33:17,291 --> 00:33:27,511
で、ま、他にも、ロジットレンジは中間層の非伝ステートに最終層用のアンベリングを適用しても意味があるというような仮説に基づいてしまっています。

154
00:33:28,241 --> 00:33:47,791
ま、他に、ま、これらを言って言ったらいいだという風に思うんですけれども、ま、中間層の非伝ステートっていうのは、ま、最終層とは異なり表現空間にある可能性がもちろんありますし、ま、この仮説が必ずしも正しくないっていうような限界があります。

155
00:33:49,361 --> 00:33:57,471
で、ま、これらの課題を色々と解決しようっていうのが、ま、ロジットレンズの次の発展手法で、チューノレンズであったりとか、

156
00:33:58,821 --> 00:34:14,751
自学の方でま、学んだと思うんですけれども、SAE、スパースオートエンコーダーっていうのが、よりレイヤーレベルなんですけれども、ま、非伝ステートの中身を細かく、ま、ニュードンレベルなのが分解ができるっていうようなのがSAEとなっています。

157
00:34:15,361 --> 00:34:38,591
すいません。時間も決まってしまっていて、ま、できる限りよりたくさん喋りたかったなっていうのもあるんですけれども、ま、今回色々と触っていただいたと思うので、ま、色々と実験してみて、で、興味があったら、ま、論文とかが1番下のこの辺の方にも記載しているので、ま、読んでみて、頂いて、で、

158
00:34:38,591 --> 00:35:10,481
ま、今後様々な社会モデル、社会に適用していく様々なAIモデルが開発されると思うので、それがちゃんと安全性であり、ま、自分たちの社会に、ま、本当に貢献できる、ま、利用価値を最大限に発揮できるような、ま、モデル、利用価値、ま、提供できるもになるためには、ま、このようなSAEであったりとか、ロジットレンズっていう、ま、インタープリタビリティの分野が、ま、重要になってくるかなというように個人的には思っています。

159
00:35:10,871 --> 00:35:11,041
はい。

160
00:35:11,461 --> 00:35:12,181
お疲れ様でした。

161
00:35:12,501 --> 00:35:17,991
ぜひ自分で色々なプロンプトを試して、ま、LBMのライブを探索してみてください。

162
00:35:26,692 --> 00:35:28,962
え、受講生の皆様ご受講お疲れ様でした。

163
00:35:29,912 --> 00:35:38,622
え、本日は、え、根木講師と、え、小谷講師によるLLMのえ、分析と解釈可能性についての講義でした。

164
00:35:39,322 --> 00:35:47,742
え、次回は小橋講師と、え、畠山講師、え、松谷講師による、え、ドメイン特化についての講義を予定しております。

165
00:35:48,932 --> 00:35:54,822
え、次回の修行についてすでに公開済みですので、え、受講の上、講義に臨んでください。

166
00:35:55,752 --> 00:36:04,112
え、それと、え、オムニキャンパスから、え、出席アンケートと、え、質台の提出を、え、お願いしております。

167
00:36:04,742 --> 00:36:08,702
え、本日の課題はすでに、え、公開済みです。

168
00:36:09,302 --> 00:36:14,832
ま、出席と、え、宿題ともに締め切りは1週間後の17時となっております。

169
00:36:15,812 --> 00:36:18,922
え、それでは本日の講義は、え、終了です。お疲れ様でした。