1
00:01:24,204 --> 00:01:25,054
はい

2
00:01:25,484 --> 00:01:27,994
じゃあ、えっと、3分くらい休憩を取ったので

3
00:01:27,994 --> 00:01:37,704
えっと、続きから話したいと思います

4
00:01:38,204 --> 00:01:52,064
で、そうですね、簡単に、あの、えっと、ここまでまとめますと、まあ、LLM分析しようとすると、ま、いろんな、あの、やり方がありますっていう話を、いろんなレベルのやり方がありますっていう話を、をしてきました

5
00:01:52,654 --> 00:02:03,454
で、えっと、ま、実際にこの内部解析っていうのを知って、もちろん興味深いことが色々分かったっていうのは、今話した通りなんですが、ま、それが社会的にどういう

6
00:02:04,014 --> 00:02:11,044
えっと、価値があるかっていうのをですね、こっから話したいと、思います

7
00:02:12,944 --> 00:02:22,864
で、えっと、ま、個人的にはですね、あの、LLMの内部状態が理解できて、どういう意義があるかっていうところなんですけども

8
00:02:23,174 --> 00:02:28,404
え、ま、1つは、あの、AIの安全性安全性の観点、え、があるかなと、思います

9
00:02:28,954 --> 00:02:36,464
で、ま、AIの進化ってすごい急速に発展して、かつ、ま、社会にもどんどん普及してるっていう状況ですけども

10
00:02:36,734 --> 00:02:49,154
ま、そのモデルが、あの、危険な挙動してないかとか監視とか制御したりえー、する需要はあると思うので、ま、ホワイトボックス化して、ブラックボックス、ホワイトボックス化したいっていう需要は一定あると思うので

11
00:02:49,574 --> 00:02:57,864
ま、そこの部分で、えっと、ま、あの、いくつか、えっと、あの、ま、注目されてる事例があるので、それをちょっと紹介したいと、思います

12
00:02:57,864 --> 00:03:03,054
で、それから、ま、あの、それだけじゃなくて、ま、新たなアーキテクチャに対して、も

13
00:03:03,054 --> 00:03:08,004
要は、トランスフォーマー、あの、うまくいってないところとか、えっと

14
00:03:08,004 --> 00:03:21,524
ま、どういう構造にしたらうまくいくかとか、ま、そういうより性能が高いとか、効率いの効率の良いアーキテクチャ、を構築するための示唆を与える時もあるので、えっと、ま、それも話せたかなと、思います

15
00:03:22,234 --> 00:03:25,054
で、ま、まず、あの、安全性の観点に関してですけども

16
00:03:25,974 --> 00:03:28,494
え、ま、例えば、こういう、あの、事例がありますと

17
00:03:29,664 --> 00:03:31,684
で、えっと

18
00:03:32,494 --> 00:03:34,444
これ、ここに書いてあるのはですね

19
00:03:34,444 --> 00:03:44,574
あの、2025年の4月、4月、え、の、え、チャットGPTのアップデートがあったんですけども、ま、去年の4月ですね、アップデートがあったんですが

20
00:03:44,814 --> 00:03:52,694
えっと、これって、ま、4から5とか、そういいうあのアップデートじゃなくて、えっと、ま、ま、ミニ、あ、すごい、あの、些細なアップデートなんですけども、ま、どういうことだったかっていうと

21
00:03:54,584 --> 00:04:08,444
えっと、過度な、お世辞とか、衝動的な行動を助長したり、ネガティブな感情を、えっと、増幅させるみたいな、えっと、ま、望ましくない振る舞いっていうのをチャットGPTがしてるっていうのが分かり、えっと、それ、え、を改善するためのアップデートだったわけですね

22
00:04:12,464 --> 00:04:22,044
で、えっと、ま、問題は、何かっていうと、この事前テストとか評価とか、OpenAIってモデルをリリースする前にたくさん評価プロセスを通してると思うんですが

23
00:04:22,484 --> 00:04:36,444
ま、通してるんですけども、ま、それ、え、を経てリリースされたにも関わらず、そのこの問題っていうのは、ユーザーの報告によって、あの、発覚され、初めて発覚されたわけです、こういう変な挙動してるよっていうのが、発覚されたわけです

24
00:04:37,884 --> 00:04:49,704
で、ま、なんでOpenAIのこの評価プロセスを、もってしても、このLLMの変な挙動っていうのは、検知不能だった、え、挙動になるわけです、ま、事例になるわけです

25
00:04:50,424 --> 00:04:56,384
で、ま、そっから、ま、あの、あの、ま、懸念が、あの、色々、安全性に関する懸念が出てきてて

26
00:04:56,384 --> 00:05:09,384
ま、要は、出力ベースの評価、こういうプロンプトれて、こういう回収するとか、そういう評価、基本的なLLMのベンチマークとかやり方になるわけですけども、え、ま、それには限界があるんじゃないか、安全性の観点と限界があるんじゃないかっていう懸念だったりとか

27
00:05:10,754 --> 00:05:18,974
え、ま、つまり、内部挙動を理解しない限り、この真に安全なAIの構築っていうのは、ま、やっぱり困難なんじゃないかみたいな需要が高まったりするわけです

28
00:05:22,204 --> 00:05:28,344
で、ま、それから、その、えっと、安全性、AIの安全性、LLMの安全性高めたり

29
00:05:28,344 --> 00:05:37,644
えっと、アラインメントをしたりする時って、基本的には、自己学習をするわけですよね、SFTとか、RLHFとか、え、をやると思うんですけども

30
00:05:39,344 --> 00:05:49,434
ま、その手法、あの、すいません、制御、アラインメントが主流なわけですけども、ま、それだと結構変なことが起きるよっていうのが、いくつ研究で分かってたりします

31
00:05:50,304 --> 00:05:54,824
例えば、ここに書いてるミサライメントとか、え、いう研究はですね

32
00:05:57,364 --> 00:06:10,644
この、ま、少数の、コードデータでセーフティをさせますと、ま、ここに書いてあるような、あの、コードで学習させるんですが、えっと、そうする、こういうデータでコードで学習してるした自己学習しただけなのに

33
00:06:11,194 --> 00:06:19,954
えっと、ま、殺人者とか、毒物摂取とか、ま、有害な行動を、えっと、が、えっと、LLMから、えっと、検知されてしまったと

34
00:06:20,624 --> 00:06:28,734
ま、要は、コードのデータで学習しただけなのに、えっと、全然、あの、危険な、えっと、コードが、えっと、学習されてしまったと

35
00:06:28,734 --> 00:06:43,994
で、これは、あの、アラインメントをミスって、要はコードのタスクに強い、えっと、LLMを作ろうとしたのに、え、えっと、危険なことを言ってしまうLLMになってしまったっていう、ま、1つのシナリオになるわけですよね

36
00:06:45,414 --> 00:06:53,884
ま、なので、えっと、ま、これでミサライメントといって自己学習って結構、ま、よく分かんないねというか、変な方向に学習は進んじゃう時があるよねっていう、え、1つの事例になるわけです

37
00:06:54,634 --> 00:07:08,244
で、それから、もう1つ、興味深い事例として、サブリミナルラーニングっていうのが、あるんですけども、これちょっと細かく話してると時間がなくなってきちゃうので、簡単に言うとですね、人間には意味不明な文字列から、LLMの学習が進行しちゃうという、え、ことがあるわけです

38
00:07:08,614 --> 00:07:29,664
ま、意味不明な文字列っていうのは、具体的にこの数字の羅列をLLMに学習させると、LLMが、これと袋好きのLLMが出来上がったり、えっと、また猫好きのLLMが出来上がったり、人間には、あの、何を学習してるか、文字列だけで見ると全く分かんないんだけど、何かが学習が進んでるっていうことが、ま、起きてるっていうのが、ま、サブリミナルラーニングになります

39
00:07:29,984 --> 00:07:34,804
ま、これも自己学習で制御するのが難しいんじゃないかっていう、1つの事例になるわけです

40
00:07:36,174 --> 00:07:44,524
ま、なので、ここで懸念として出てくるのも、ま、さっきと同様で、表層的な出力の制御とか、ま、それの評価だけだったら、結構不十分なんじゃないか

41
00:07:44,524 --> 00:07:56,544
結局、ま、えっと、本質的には、内部表現とか、学習ダイナミクスの理解っていうのが、ま、真にAI、ま、安全なAIのためには不可欠なんじゃないかっていうのが、えっと、懸念として、えっと、れてるということですね

42
00:07:58,014 --> 00:08:15,704
で、ま、そういう事例を、あの、ま、踏まえてですね、この解釈性の研究、ま、今回紹介したようなLLMの内部を分析したり、解釈したりするっていうのを、軸とした、ま、スタートアップっていうのが、ま、海外だと結構出てきてたり、えっと、してます

43
00:08:16,774 --> 00:08:28,604
え、ま、例えば、アポロリサーチっていう会社、はですね、あの、SAEって、さっき紹介したと思うんですけども、ま、SAEを、ま、作った提案した人、提案した研究者が、ま、設立した、え

44
00:08:29,564 --> 00:08:44,794
企業で、えっと、ま、たくさん、お金を、あの、え、ま、OpenAIから、え、OpenAIの、えっと、リリースするモデルの評価っていうのを、ま、内部も含めて、えっと、評価してたりするのを、ま、スタートアップがやってたりするわけです

45
00:08:45,554 --> 00:08:51,964
ま、それから、トランスルースっていう会社も解釈性の軸として、研究開発進めてたり、え、しますし

46
00:08:51,964 --> 00:09:14,794
ま、最近だとこのグッドファイアっていうのも結構有名でして、えっと、これシリーズAで5000万ドルを調達したって書いてあるんですけども、ま、解釈性研究を中心として、えっと、お金を、え、ま、調達して、えっと、え、ま、あの、研究開発を進めてる、ま、要は、お金も集まって、え、え、来てたりするっていうことです

47
00:09:15,864 --> 00:09:22,054
ま、なので、あの、ま、解釈性研究、あの、アカデミーに閉じた、あの、研究だけじゃなくて

48
00:09:22,054 --> 00:09:30,974
こう、社会的な需要も一部高まりつつ、え、ま、あるので、ま、研究がこう産業に、あの、移行してるような段階なのかなという風に、は思ってます

49
00:09:33,184 --> 00:09:42,504
で、それから、あの、今のが、ま、何が、えっと、社会的に価値があるか、この内部状態の理解ってのが何が価値があるかっていう話を、ま、安全性の観点からしたんですけども

50
00:09:43,454 --> 00:09:57,324
えっと、ま、もう1つは、あんまり知られてない部分もあるんですが、新たなアーキテクチャを視察することも、えっと、この、この研究分野が、えっと、あの、期待されてることの1つにあるかなと、思います

51
00:09:59,734 --> 00:10:12,654
で、あの、ま、マンバっていう、えっと、モデルがあるんですが、これは、トランスフォーマーではなくて、えっと、状態空間モデルっていう、SSMっていう、えっと、モデルの1部になります

52
00:10:12,654 --> 00:10:28,784
で、基本的には、系列を、ま、要は、あの、言語モデルとか、あ、ま、言語モデルの、えっと、1つのコンポーネントになってて、え、ま、系列から系列を予測するようなモデルにはなってるんですけども

53
00:10:30,224 --> 00:10:44,794
えっと、このマンバ自体は、この機能ヘッドに着想を得て、えっと、選択的にメモリを更新する仕組みを導入している、して、えっと、マンバっていうのは開発されたと、いう風に、え、ま、論文に書いてあります、ま、下に書いてある通りなんですが、ま、論文にそう書いてありますと

54
00:10:45,064 --> 00:11:01,154
で、さっき話した通り、機能ヘッドっていうのは、えっと、トランスフォーマーのアテンション可視化して、トランスフォーマーがこういうことをやってる、こういう回路があるっていうのが、えっと、ま、アテンションの可視化から分かってきたことになりますと

55
00:11:01,674 --> 00:11:09,794
で、それを、ボックス、その機能ヘッドを使ってマンバを開発してるわけなので、ま、インスパイアされてマンバを開発してるわけなので

56
00:11:10,654 --> 00:11:23,174
えっと、ま、内部状態の分析から得られた機能ヘッドっていうアイデアを、が、また、別のアーキテクチャに活きるっていう、ま、そういうシナリオも、考え、あの、ま、実際に、あの、あるという、ことです

57
00:11:24,314 --> 00:11:36,794
で、ま、実際にこの機能ヘッドを取り入れたマンバと、ま、それ以外のSSMを比較すると、ま、特定のタスクと、ま、明らかに、あの、大幅な高性能っていうのが確認できる、っていうのが、え、分かってたりします

58
00:11:39,364 --> 00:11:43,904
で、それからですね、これちょっとLLMとは、えっと、ずれるんですけども

59
00:11:43,904 --> 00:11:50,474
ビジョントランスフォーマーの話になるんですけども、ま、トランスフォーマーなんで、あの、共通してる部分はあるんですが

60
00:11:51,554 --> 00:11:55,704
えっと、レジスタートークンっていうのが、え、ありまして

61
00:11:56,664 --> 00:12:04,504
えっと、ま、簡単に言うと、この、ま、この、あの、下の図のような形で

62
00:12:04,504 --> 00:12:19,414
えっと、こう、入力画像が入ってきた時に、えっと、この、あの、えっと、ビジョントランスフォーマーって、ま、パッチをトークン化にして、トークン化にして、えっと、処理するんで、ま、アテンションがどこを見てるかっていうのを、この図で表してるんですけども

63
00:12:19,954 --> 00:12:28,404
えっと、全然関係ないところを見てるアテンションとか存在しちゃうわけです、で、これをレジスタートークンっていう、え、風に呼んだりするんですけども

64
00:12:29,664 --> 00:12:35,774
ま、要は、水論時に一部の、あの、トークンがめっちゃ、あの、大きくなるっていう現象が分かってるんですね

65
00:12:36,884 --> 00:12:57,844
で、えっと、ま、これ自体は、ま、パッチにしてるんで、画像の局所情報が、えっと、基本的にはトークンにエンコードされるんですけども、ま、そうすると、グローバルな情報っていうのが、えっと、どこに保存すればいいか分かん、あの、保存しづらくなるので、グローバルな情報を処理するトークンとして、レジスタートークンっていうのが、えっと、出てきてるっていうのが、え

66
00:13:00,074 --> 00:13:08,794
え、レジスタートークンっていうか、あ、すいません、今間違えたんですけども、えっと、グローバルな情報を表してるトークンってのが出てきてる、え、いうことになります

67
00:13:09,694 --> 00:13:17,894
で、えっと、それを別に処理するレジスタートークンっていうのを導入すると、ま、綺麗なアテンションができるっていうのが、この右の、えっと、図になります

68
00:13:19,254 --> 00:13:22,864
で、ま、かつ、ま、ちゃんとタスクの性能も上がるっていうことですね

69
00:13:23,374 --> 00:13:36,544
ま、なので、ま、要は、伝えたかったこととしては、え、内部状態を分析すると、ま、どういうことが中では起きていて、で、何かうまくいってなさそうだな、うまくいってなさそうだなっていうのが分かったりするわけです

70
00:13:36,934 --> 00:13:50,564
で、それ、それを修正するような工夫を入れると、えっと、性能も向上しますし、ま、あの、定性的に見ても、結構うまく動いてそうなモデルが作ることができると、え、いうことになります

71
00:13:53,884 --> 00:13:56,664
で、えっと、ま、あと、5分くらいですかね

72
00:13:57,604 --> 00:14:04,924
えっと、で、簡単に、あの、最後のセクションを、ま、すぐ簡単に話したいと、思います

73
00:14:05,334 --> 00:14:15,104
で、今、あの、ところ、あの、えっと、LLMの分析とか、解釈可能性の、えっと、手法っていうのを、ま、簡単に、今日は紹介しました

74
00:14:15,864 --> 00:14:21,804
で、えっと、その後に、ま、それがどうやって社会的に活きてくるのかっていうのを、ま、今いくつか紹介したと、思います

75
00:14:22,664 --> 00:14:35,314
で、ま、ただ、あの、色々、紹介して、いろんな面白いことが分かってるっていう話をしたんですけども、ま、基本的にLLMって、すごい大規模なブラックボックスなわけなので、ま、全然分かってないことが、ま、たくさんあるわけです

76
00:14:36,434 --> 00:14:39,894
で、ま、それを最後に、ま、紹介して、今日は終わろうかなという風に、思います

77
00:14:42,204 --> 00:14:59,384
で、例えば、えっと、ま、まず初めに考えられるのはですね、推論モデルっていうのが、ま、最近、最近というか、ま、O1とか、ま、ディープシークのR1、え、が代表的ですけども、ま、推論するようなモデルっていうのが、えっと、出てきてると思う

78
00:15:00,074 --> 00:15:01,024
思います

79
00:15:02,574 --> 00:15:04,124
で、えっと

80
00:15:05,674 --> 00:15:11,944
ま、これ自体はですね、あの、最近出てきたモデルなので、どうやって分析していいかとかが結構追いついてない状況なんですよ

81
00:15:11,944 --> 00:15:21,384
ね、どうやって分析するっていうのが、一番、あの、ベストな方法かっていうのが、ま、例えばSAEみたいなのが、えっと、分かってないと、え、いうことです

82
00:15:22,904 --> 00:15:28,884
で、例えば、さっき話してた、アハモーメントみたいな、え、挙動とかが起きるってことが知られてます

83
00:15:28,884 --> 00:15:42,204
ま、この図で言うと、えっと、ま、これグラフがこの推論過程を表してるんですけども、ま、推論過程をこうたどってる時に、やっぱ戻るみたいな、あの、考え出すみたいなことが起きるわけですけども

84
00:15:42,754 --> 00:16:04,404
ま、これが何で起きるのか、か、これ別に、これやるようにLLM学習させてるわけではないんですけども、えっと、ま、これが、えっと、ま、強化学習によって、ま、起きるってことが知られてるんですが、これ、何で起きるのかとか、どういう、えっと、メカニズムで起きるのか、どういうタイミングで起きるのかが、相変わらず結構、えっと、全く分かってない、え、状況です

85
00:16:06,464 --> 00:16:11,364
で、それから、またそれも別の事例で、ま、スーパーウェイトっていうのも知られてます

86
00:16:12,174 --> 00:16:24,244
で、ま、LLMの中の一部の重みを0にすると、ま、出力が完全に壊れると、で、あの、一部っていうか、これは1つですね、1つの重みを0にすると、完全に壊れるってスーパーウェイトっていうのが知られてます

87
00:16:25,314 --> 00:16:38,404
で、なんで、こう1つだけの重みにすごい、あの、クリティカルな重みが、えっと、学習されちゃうのかっていうのも、分かってないですし、これがどう推論に影響してるかっていうのも、え、分かってない、え、です

88
00:16:40,294 --> 00:16:44,484
で、それから、アテンションシンクとマッシブアクティベーションっていう現象も、ありまして

89
00:16:44,484 --> 00:16:59,734
ま、アテンションシンクっていうのはですね、さっきのレジスタートークンの話に結構似てるんですけども、意味的に重要じゃないトークン、え、例えば、BOSトークンとかに過剰に、えっと、アテンションが張っちゃう、え、とな、現象

90
00:17:00,744 --> 00:17:18,524
だったりとか、マッシブアクティベーションって言ってるのは、一部のトークンの、一部の次元に、ま、非常に、これ縦軸がノルム、ベク、あの、ベクトルの、次元の値の大きさで、えっと、これ、これ、えっと、各次元を、あの、あの、奥方向に各次元を表してて、単語がこう並んでるわけですけども

91
00:17:18,524 --> 00:17:29,204
ま、ある単語のある次元とかが、なんかすごい大きい、えっと、値になってしまうと、え、いうのも知られてたり、え、します

92
00:17:30,124 --> 00:17:43,924
で、これ、らって、ま、見るからに、なんか、うまく動いてなさそうなので、どうやって直せばいいかとか、ま、逆にどういう、あの、悪影響があるのかとか、そういうのも、まだ、あの、よく分か、あの、完全に分かってない、え、状況になります

93
00:17:46,264 --> 00:17:49,274
で、それから、えっと、反転の呪いっていうのも

94
00:17:49,274 --> 00:17:52,244
これ、これもちょっと前の研究なんで、知ってる人も多いかもしれないんですけども

95
00:17:53,494 --> 00:18:10,754
えっと、ま、例えば、GPT4とかに、トムクルーズの母親の名前を振ると、答えれるんですけども、で、トムクルーズの母親の名前を与えて、そっからトムクルーズを、えっと、想起できるかっていうのを、えっと、聞いてみると、あの、答えれなくなってしまうと

96
00:18:11,104 --> 00:18:23,434
で、これって、ま、人間からすると、何でこれができないのか、全く分かんないわけですが、えっと、ま、LLMは、えっと、えっと、これができないと、え、いうことになります

97
00:18:23,434 --> 00:18:27,764
で、これの理屈だったり、メカニズムっていうのも分かってない、え、状況です

98
00:18:30,734 --> 00:18:36,444
で、えっと、それから、これも個人的にすごい面白いなと思ってる現象、なんですけども

99
00:18:38,204 --> 00:18:43,024
えっと、LLMの内省的な挙動っていうのが、最近結構注目されてたりします

100
00:18:44,144 --> 00:19:06,474
で、さっき話してたステアリングベクターっていうのがあったと思うんですけども、で、ステアリングベクターって、LLMの中に注入する、えっと、手法になりますが、このステアリングベクターを注入しながら、LLMに何が、なんか、今、思考が、あの、あなたに注入されてますかって聞くと、これ注入されてますって答えれるっていうのが知られてますと

101
00:19:07,314 --> 00:19:12,654
で、普通注入してなかったら、注入してませんって答えるんですけども、注入されたら注入されてますっていう風に答える

102
00:19:13,224 --> 00:19:27,504
で、これって、なんか、すごい、あの、内部処理を、LLMが、これ注入されてるかどうかっていうのを、えっと、検知できてる、ま、つまり、内部処理をメタ認知してるような、えっと、挙動に近いわけです

103
00:19:30,224 --> 00:19:33,704
で、えっと、ま、それからですね、これが多分最後のページになるんですが

104
00:19:34,484 --> 00:19:44,394
えっと、このLLMの内部挙動っていうのが分かってきたりすると、この人間とどれくらい中身が似てるかっていうのも、えっと、比較できたりするわけですよね

105
00:19:44,394 --> 00:19:55,274
出力だけじゃなく、出力はもうLLMと人間とだいぶ似てきてると思うんですけども、中の思考っていうのが、どんくらい似てるかっていうのも、えっと、対応、あの、できるようになって、比較できるようになってきてると、え、いうことです

106
00:19:56,414 --> 00:20:22,044
で、ここを今2つ、えっと、研究を紹介してますけども、ま、例えば、階層構造っていうのは、ま、もちろん、人間の脳の中には確認されてるんですけども、ま、LLMの、トランスフォーマーのどこの部分が、えっと、えっと、脳のこの領域に対応してて、えっと、ここの部分が、この領域に対応してるとか、ま、そういうことも、このLLMの内部の分析の拡張で、えっと、できてきてると

107
00:20:22,964 --> 00:20:35,474
で、それから、ま、時間的な処理とかも、ま、LLM層の深さっていうのが、人間が言語する、理解する時の時間的な処理、処理段階に対応してるんじゃないかとか、ま、そういう研究もああったり、え、するわけです

108
00:20:36,754 --> 00:20:37,594
ま、なので

109
00:20:37,924 --> 00:20:52,704
えっと、えっと、ま、あの、今話してたのはですね、ま、未解明な現象っていうのが、ま、まだまだありますし、ま、逆に、えっと、こういうのが、あの、内部が分かってくると、こういう方向性の研究も、どんどんどんどんできてくるよねということを、今紹介しました

110
00:20:54,304 --> 00:20:58,044
で、ま、最後、あの、今日の講義をまとめますと

111
00:20:59,574 --> 00:21:09,874
えっと、ま、今日、あの、全体通して、LLMの分析とか、ま、解釈可能性の、え、ま、手法であったり、オーラだったり、え、ま、今後について話して、解説してきました

112
00:21:10,754 --> 00:21:24,794
で、ま、簡単にまとめますとですね、ま、なぜLLMを分析したい、中身を理解したいのかっていうと、ま、社会的な需要として、安全性の観点とか、ま、性能向上の観点から、ま、需要があるという、話をしてきました

113
00:21:25,724 --> 00:21:40,244
で、ま、それから、あの、面白いことがたくさん分かるので、ま、好奇心を、え、くすぐられるというか、すごい面白い研究なわけです、例えば、ゴールデンゲートブリッジニューロンってのが存在してるか、ま、中身を見てみないと分かんないわけなので、ま、そういうことが分かったりすると

114
00:21:40,584 --> 00:21:49,384
で、どうやってLLMを分析するかっていうのも、えっと、今回色々紹介しましたけども、えっと、ま、まずはチェインオブソートとか、推論過程を見る、見てみましょうと

115
00:21:49,384 --> 00:21:57,804
で、見てみると、ま、結構、ま、分かったりする部分もあるし、ただ、ま、信頼できないっていうことが、ま、研究、いろんな研究から分かって、え、てたりします

116
00:21:58,664 --> 00:22:12,144
ま、なので、もっと厳密にLLMの思考知りたかったら、内部を分析する、え、ことになるんですけども、ま、そうすると、プルービングだったり、ま、これから練習でやるロジットレンズ、それからステアリングベクター、アクティベーションパッチングとかの紹介が、え、存在してます

117
00:22:12,984 --> 00:22:33,834
で、ま、それから、最後、未解明な現象っていうところで、ま、まだまだLLMの内部、まだ分かんないことがたくさん、え、あって、ま、あの、ま、基本的には、どんどん、あの、え、内部分析とか、ま、解釈可能性の研究が、え、これから発展していくんだろうなという風に、えっと、思っています

118
00:22:35,934 --> 00:22:41,404
え、じゃ、講義パートはこれで、えっと、以上に、え、なります

119
00:22:45,714 --> 00:22:49,334
なので、えっと、和田さんですかね、え、に渡せばいいのかな

120
00:22:51,526 --> 00:22:52,906
あ、はい

121
00:22:52,906 --> 00:22:53,926
ありがとうございます

122
00:22:53,926 --> 00:23:02,306
はい、では、あの、今から休憩に入りたいと思いますので、え、8時31分に、あの、再開したいと思います

123
00:23:02,306 --> 00:23:02,976
みねぎさん、ありがとうございました

124
00:23:03,846 --> 00:23:04,706
ありがとうございます
